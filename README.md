# Enterprise AI NLP Solution

## ğŸ“Œ Overview

This project implements an **Enterprise AI NLP Solution** for financial data analytics with both **batch and real-time capabilities**.  

It features a complete data pipeline that:  
- Ingests data from **PostgreSQL**, **live data sources**, and **Kafka streaming**  
- Processes data with **Apache Spark**  
- Orchestrates workflows using **Airflow**  
- Applies **NLP and ML models**  
- Stores results in **Snowflake**  
- Visualizes insights in **Tableau BI dashboards**

---

## ğŸ”„ Pipeline Flow

**Batch Processing:**  

PostgreSQL â†’ Spark ETL â†’ Airflow DAGs â†’ NLP Models â†’ ML Predictions â†’ Tableau Dashboards


**Real-Time Streaming:**  

Live Data APIs â†’ Kafka Topics â†’ Spark Structured Streaming â†’ Snowflake â†’ NLP Models â†’ ML Predictions â†’ Alerts â†’ Tableau Dashboards


---

## ğŸ“‚ Project Structure

Enterprise-AI-NLP-Solution/
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â”œâ”€â”€ finance_etl_dag.py # Batch ETL pipeline
â”‚ â”‚ â”œâ”€â”€ load_stock_data_dag.py # PostgreSQL ingestion
â”‚ â”‚ â””â”€â”€ streaming_dag.py # Real-time streaming
â”‚ â”œâ”€â”€ logs/
â”‚ â””â”€â”€ plugins/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ finance_data.csv # Raw batch data
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ nlp/
â”‚ â”‚ â”œâ”€â”€ sentiment_analysis.py
â”‚ â”‚ â”œâ”€â”€ document_classifier.py
â”‚ â”‚ â””â”€â”€ chatbot_llm.py
â”‚ â”œâ”€â”€ ml/
â”‚ â”‚ â””â”€â”€ prediction_pipeline.py
â”‚ â”œâ”€â”€ database/
â”‚ â”‚ â””â”€â”€ postgres_loader.py
â”‚ â”œâ”€â”€ spark/
â”‚ â”‚ â”œâ”€â”€ spark_etl.py
â”‚ â”‚ â””â”€â”€ spark_streaming.py
â”‚ â”œâ”€â”€ streaming/
â”‚ â”‚ â”œâ”€â”€ kafka_producer.py
â”‚ â”‚ â””â”€â”€ kafka_consumer.py
â”‚ â””â”€â”€ snowflake/
â”‚ â””â”€â”€ snowflake_loader.py
â”œâ”€â”€ tableau/
â”‚ â””â”€â”€ finance_dashboards.twbx
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_database.py
â”‚ â”œâ”€â”€ test_spark_etl.py
â”‚ â”œâ”€â”€ test_nlp_models.py
â”‚ â””â”€â”€ test_prediction_pipeline.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ .github/
â””â”€â”€ workflows/
â””â”€â”€ ci-cd.yml


---

## ğŸš€ Features

### 1. Data Ingestion
- **Batch:** Load financial data from PostgreSQL  
- **Streaming:** Ingest live stock prices, news, and alerts using Kafka  

### 2. ETL & Stream Processing
- Apache Spark for **batch ETL** (`src/spark/spark_etl.py`)  
- Spark Structured Streaming for **real-time data** (`src/spark/spark_streaming.py`)  

### 3. Workflow Orchestration
- Airflow DAGs for batch + streaming pipelines  

### 4. NLP Models
- Sentiment analysis (`src/nlp/sentiment_analysis.py`)  
- Document classification (`src/nlp/document_classifier.py`)  
- Chatbot/LLM interactions (`src/nlp/chatbot_llm.py`)  

### 5. Machine Learning Predictions
- Real-time and batch ML pipelines for financial predictions  

### 6. BI Dashboards
- Tableau dashboards for **financial insights & alerts**  

### 7. Streaming & Alerts
- Real-time alerts via **email, Slack, or webhooks**  
- Kafka topics:  
  - `stock_prices`  
  - `news_sentiment`  
  - `alerts`  

### 8. Enterprise Storage & Security
- **Snowflake** for secure, scalable cloud storage  
- **Encryption at rest + in transit**  
- **Role-based access control (RBAC)**  
- **Secret management** via Airflow Secrets or Vault  
- **Kafka SSL/SASL** for secure streaming  

---

## âš™ï¸ Setup & Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/Enterprise-AI-NLP-Solution.git
cd Enterprise-AI-NLP-Solution

    Install dependencies:

pip install -r requirements.txt

    Start Docker services:

docker-compose up -d

    Access Airflow UI:
    ğŸ‘‰ http://localhost:8080

    Trigger batch & streaming pipelines via Airflow DAGs.

ğŸ§ª Running Tests

Run all tests:

pytest tests/

ğŸ”„ CI/CD

GitHub Actions (.github/workflows/ci-cd.yml) handles:

    âœ… Linting

    âœ… Unit tests

    âœ… Docker build & deployment

ğŸ³ Docker & Service Management
Start all services

docker-compose up --build -d

Stop and remove everything

docker-compose down -v

View logs

docker logs -f nlp_app
docker logs -f kafka_producer
docker logs -f kafka_consumer
docker logs -f postgres_container

Connect to PostgreSQL inside Docker

docker exec -it postgres_container psql -U postgres -d finance_db

Example SQL:

\dt;
SELECT * FROM transactions LIMIT 10;

ğŸ— Architecture Diagram

                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Live APIs  â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                â”‚   Kafka     â”‚
                â”‚ (Streaming) â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚               â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ Spark ETL   â”‚ â”‚ Spark Streamâ”‚   â”‚   Airflow   â”‚
â”‚ (Batch)     â”‚ â”‚ Processing  â”‚   â”‚ Orchestration â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚               â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚ NLP & ML    â”‚
       â”‚ Models      â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚ Snowflake   â”‚
       â”‚ (Storage)   â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚ Tableau BI  â”‚
       â”‚ Dashboards  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¤ Contributing

    Fork the repo

    Create feature branch

git checkout -b feature/my-feature

    Commit changes

git commit -am "Add new feature"

    Push branch

git push origin feature/my-feature

    Open Pull Request

ğŸ“œ License

This project is licensed under the MIT License.
See LICENSE
for details.